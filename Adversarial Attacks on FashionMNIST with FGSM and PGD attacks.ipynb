{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f776cd94-3491-421b-8fb6-053c01761c62",
   "metadata": {},
   "source": [
    "# Adversarial Attacks on FashionMNIST with FGSM and PGD attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b75849c-9626-4a81-97b1-557d6f53ddae",
   "metadata": {},
   "source": [
    "In this notebook, we perform FGSM (targeted and non-targeted) and PGD attacks on the FashionMNIST dataset using the Resnet18 model and build models to defend against these attacks using the Adversarial Training mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb647e8-f965-466c-bc8b-c26684cc8dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import *\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from resnet_mnist import *\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ae8125-9713-46b5-879e-f9d3abf2c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9443f6e-7eef-4e38-8b3b-473239655a48",
   "metadata": {},
   "source": [
    "<a name='name'></a>\n",
    "### Preparing train and test data and building Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132059ed-96fa-49bb-bc07-5ccd824bbca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "# Transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# FashionMNIST dataset\n",
    "trainset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(\n",
    "    testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# Use ResNet18 with 10 output classes for FashionMNIST\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ff1ddd-a022-4a18-b084-820abc6e3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, net):\n",
    "    \n",
    "    '''\n",
    "    this function train net on training dataset\n",
    "    '''\n",
    "\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_accuracies = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "    return train_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa2b9cb1-3981-4809-b60b-77a7e5163043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, net):\n",
    "\n",
    "    '''\n",
    "    This function evaluate net on test dataset\n",
    "    '''\n",
    "\n",
    "    global acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_accuracies = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return test_loss/len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bef1de-130f-4356-9ce3-c28fc0a317be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses=[]\n",
    "test_losses=[]\n",
    "epochs=3\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    train_losses.append(train(epoch, net))\n",
    "    test_losses.append(test(epoch, net))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f431f7-21fd-41d5-85f0-0ab0d1d46aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043d528-e9f6-4959-8426-e8844c3c6756",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=3\n",
    "plt.plot(np.arange(1,epochs+1),train_losses, label='train losses')\n",
    "plt.plot(np.arange(1,epochs+1), test_losses, label='test losses')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf0ed7-21c1-424a-8a78-03de5b6e1997",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    accuracy = acc  # Assuming 'acc' is a global variable in your existing code\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb7f72-38d7-4548-a4c0-ee603dd78eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), accuracies, label='Accuracy', marker='o')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb63f6f7-1f97-49ce-9154-4b1406057010",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=30, shuffle=False, num_workers=2)\n",
    "dataiter = iter(imgloader)\n",
    "org_images, org_labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29497286-ff97-48c8-9bf6-04e9dacd0b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 1, 28, 28])\n",
      "torch.Size([30, 10])\n"
     ]
    }
   ],
   "source": [
    "org_labels = org_labels.to(device)\n",
    "org_images = org_images.to(device)\n",
    "print(org_images.shape)\n",
    "outputs= net(org_images)\n",
    "output=outputs.to(device)\n",
    "print(outputs.shape)\n",
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f51afcc-bb15-4b1a-a2fa-46b3755ca28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "samples = []\n",
    "samples_labels = []\n",
    "samples_pred = []\n",
    "selected = [3,0,26,16,4,13,1,11]\n",
    "\n",
    "for i in selected:\n",
    "  samples.append(org_images[i])\n",
    "  samples_labels.append(org_labels[i])\n",
    "  samples_pred.append(outputs[i])\n",
    "samples = torch.stack(samples)\n",
    "samples_labels = torch.stack(samples_labels)\n",
    "samples_pred = torch.stack(samples_pred)\n",
    "imshow(torchvision.utils.make_grid(samples.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d335c-abe7-46fc-a204-1aa9b3522d82",
   "metadata": {},
   "source": [
    "### FGSM attack function\n",
    "In the FGSM attack, we make adversarial examples using this equation:\n",
    "$x_{adv}=x_{benign}+\\epsilon * sign(\\nabla_{x_{benign}}l(\\theta, x, y))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c687fc37-4493-4321-bce2-7896bbbf710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(net, x, y, eps):\n",
    "        '''\n",
    "        inputs:\n",
    "            net: the network through which we pass the inputs\n",
    "            x: the original example which we aim to perturb to make an adversarial example\n",
    "            y: the true label of x\n",
    "            eps: perturbation budget\n",
    "\n",
    "        outputs:\n",
    "            x_adv : the adversarial example constructed from x\n",
    "            h_adv: output of the last softmax layer when applying net on x_adv \n",
    "            y_adv: predicted label for x_adv\n",
    "            pert: perturbation applied to x (x_adv - x)\n",
    "        '''\n",
    "\n",
    "        x_ = Variable(x.data, requires_grad=True)\n",
    "        h_ = net(x_)\n",
    "        criterion= torch.nn.CrossEntropyLoss()\n",
    "        cost = criterion(h_, y)\n",
    "        net.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        #perturbation\n",
    "        pert= eps*x_.grad.detach().sign()\n",
    "        \n",
    "        x_adv = x_ + pert\n",
    "\n",
    "        h_adv = net(x_adv)\n",
    "        _,y_adv=torch.max(h_adv.data,1)\n",
    "        return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce57a2-ebab-4082-8527-6712991746b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print()\n",
    "print('from left to right: (1/eps) perturbation, original image, adversarial example')\n",
    "print()\n",
    "for i in selected:\n",
    "    eps=1/255\n",
    "    while True:\n",
    "        x_adv, h_adv, y_adv, pert=FGSM(net, org_images[i].unsqueeze_(0),org_labels[i].unsqueeze_(0),eps)\n",
    "        if y_adv.item()==org_labels[i].item():\n",
    "            eps=eps+(1/255)\n",
    "        else:\n",
    "            break\n",
    "    print(\"true label:\", org_labels[i].item(), \"adversary label:\", y_adv.item())\n",
    "    triple=[]\n",
    "    with torch.no_grad():\n",
    "        triple.append((1/eps)*pert.detach().clone().squeeze_(0))\n",
    "        triple.append(org_images[i])\n",
    "        triple.append(x_adv.detach().clone().squeeze_(0))\n",
    "        triple=torch.stack(triple)\n",
    "        grid = torchvision.utils.make_grid(triple.cpu()/2+0.5)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba91591-38a3-4722-a726-40763130974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Building new model..')\n",
    "net_adv = ResNet18()\n",
    "net_adv = net_adv.to(device)\n",
    "if device == 'cuda':\n",
    "    net_adv = torch.nn.DataParallel(net_adv)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_adv = optim.SGD(net_adv.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler_adv = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_adv, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4638cf-8889-4295-ba16-5eb49320677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adv(epoch, net):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    eps=8/255\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs_ = Variable(inputs.data, requires_grad=True)\n",
    "        h_ = net(inputs_)\n",
    "\n",
    "        cost = criterion(h_, targets)\n",
    "\n",
    "        net.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        pert= eps*inputs_.grad.detach().sign()\n",
    "        x_adv = inputs_ + pert\n",
    "\n",
    "        optimizer_adv.zero_grad()\n",
    "        outputs = net(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_adv.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "    return train_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42a54c-aca9-4af9-8979-270dc2b6c3c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_adv=[]\n",
    "test_losses_adv=[]\n",
    "epochs=3\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    train_losses_adv.append(train_adv(epoch, net_adv))\n",
    "    test_losses_adv.append(test(epoch, net_adv))\n",
    "    scheduler_adv.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f5017-de8d-4ad8-a13f-4dd363fb24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on unperturbed test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cd596-df3f-4a96-8d6e-e23139ad89f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,epochs+1),train_losses_adv, label='train - adversary')\n",
    "plt.plot(np.arange(1,epochs+1), test_losses_adv, label='test - adversary')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826d20d-5564-4b29-9ccc-19edb84b389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adv(net, net_adv, eps):\n",
    "    accuracy=0\n",
    "    net.train()\n",
    "    net_adv.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv, h_adv, y_adv, pert = FGSM (net, inputs, targets, eps)\n",
    "            \n",
    "        outputs = net_adv(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a29598-36f4-469e-b899-6b31d3c3dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in [4/255, 8/255, 12/255]:\n",
    "    accuracy=test_adv(net, net_adv, eps)\n",
    "    print(\"epsilon:\", eps, \"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ca6d62-f35f-4e66-a67d-891ddab6c822",
   "metadata": {},
   "source": [
    "### Defense Mechanism - Gaussian Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2de70d3-4954-4b0f-8349-d3b406966fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_with_AdvancedGaussianDefense(net, x, y, eps, sigma=0.1, alpha=0.2):\n",
    "    '''\n",
    "    inputs:\n",
    "        net: the network through which we pass the inputs\n",
    "        x: the original example which we aim to perturb to make an adversarial example\n",
    "        y: the true label of x\n",
    "        eps: perturbation budget\n",
    "        sigma: standard deviation of the Gaussian noise\n",
    "        alpha: spatially varying factor for Gaussian noise\n",
    "\n",
    "    outputs:\n",
    "        x_adv : the adversarial example constructed from x with advanced Gaussian defense\n",
    "        h_adv: output of the last softmax layer when applying net on x_adv \n",
    "        y_adv: predicted label for x_adv\n",
    "        pert: perturbation applied to x (x_adv - x)\n",
    "    '''\n",
    "\n",
    "    x_ = torch.autograd.Variable(x.data, requires_grad=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    h_ = net(x_)\n",
    "    \n",
    "    # Calculate the cross-entropy loss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    cost = criterion(h_, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    net.zero_grad()\n",
    "    cost.backward()\n",
    "    \n",
    "    # Perturbation using FGSM\n",
    "    pert = eps * x_.grad.detach().sign()\n",
    "    \n",
    "    # Create a spatially varying defense factor\n",
    "    defense_factor = alpha * torch.randn_like(x_)\n",
    "    \n",
    "    # Apply spatially varying Gaussian defense to the perturbation\n",
    "    pert = pert + defense_factor * sigma\n",
    "    \n",
    "    # Create the adversarial example\n",
    "    x_adv = x_ + pert\n",
    "    \n",
    "    # Forward pass on the adversarial example\n",
    "    h_adv = net(x_adv)\n",
    "    \n",
    "    # Get the predicted label for the adversarial example\n",
    "    _, y_adv = torch.max(h_adv.data, 1)\n",
    "    \n",
    "    return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372dcd64-e509-47d9-92b7-aefd53bf542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adv_d(epoch, net):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sigma = 0.2\n",
    "    eps = 8 / 255\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs_ = torch.autograd.Variable(inputs.data, requires_grad=True)\n",
    "        h_ = net(inputs_)\n",
    "\n",
    "        cost = criterion(h_, targets)\n",
    "\n",
    "        net.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        # Perturbation using FGSM\n",
    "        pert = eps * inputs_.grad.detach().sign()\n",
    "        \n",
    "        # Apply Gaussian defense to the perturbation\n",
    "        pert = pert + torch.randn_like(inputs_) * sigma\n",
    "\n",
    "        x_adv = inputs_ + pert\n",
    "\n",
    "        optimizer_adv.zero_grad()\n",
    "\n",
    "        # Forward pass on the adversarial example\n",
    "        outputs = net(x_adv)\n",
    "\n",
    "        # You may want to apply Gaussian defense to the adversarial example here\n",
    "        pert_adv = torch.randn_like(x_adv) * sigma\n",
    "        x_adv = x_adv + pert_adv\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_adv.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "    \n",
    "    return train_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d91fcf-5c50-405c-ab40-7684c02234a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_adv_g = []\n",
    "test_losses_adv_g = []\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses_adv_g.append(train_adv_d(epoch, net_adv))\n",
    "    test_losses_adv_g.append(test(epoch, net_adv))\n",
    "    scheduler_adv.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad73f89-3d3c-4c82-aff6-24b5f366d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on unperturbed test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0fbe7-6e39-49d5-907c-35ef89e4db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,epochs+1),train_losses_adv_g, label='train - adversary')\n",
    "plt.plot(np.arange(1,epochs+1), test_losses_adv_g, label='test - adversary')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7697f9-818d-4ef7-9ffe-a47ddc6195b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adv_d(net, net_adv, eps, sigma=0.1):\n",
    "    accuracy = 0\n",
    "    net.train()\n",
    "    net_adv.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Call FGSM_with_AdvancedGaussianDefense to generate adversarial examples\n",
    "        x_adv, h_adv, y_adv, pert = FGSM_with_AdvancedGaussianDefense(net, inputs, targets, eps, sigma)\n",
    "\n",
    "        outputs = net_adv(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0663773-dd32-4413-b085-a8e94318228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in [4/255, 8/255, 12/255]:\n",
    "    accuracy = test_adv_d(net, net_adv, eps, sigma=0.1)\n",
    "    print(\"epsilon:\", eps, \"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46dcc7e-a27e-4347-926e-ac1e1c3d2d0e",
   "metadata": {},
   "source": [
    "### Defense Mechanism - Defense Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437181c5-fc2c-497b-b1f2-1bdf89b3f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_defense_distillation(net, teacher_model, x, y, eps, temperature=3.0):\n",
    "    '''\n",
    "    inputs:\n",
    "        net: the student network through which we pass the inputs\n",
    "        teacher_model: the pre-trained teacher model for defense distillation\n",
    "        x: the original example which we aim to perturb to make an adversarial example\n",
    "        y: the true label of x\n",
    "        eps: perturbation budget\n",
    "        temperature: temperature parameter for softmax\n",
    "\n",
    "    outputs:\n",
    "        x_adv : the adversarial example constructed from x\n",
    "        h_adv: output of the last softmax layer when applying net on x_adv \n",
    "        y_adv: predicted label for x_adv\n",
    "        pert: perturbation applied to x (x_adv - x)\n",
    "    '''\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    net.eval()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Forward pass through the teacher model\n",
    "    with torch.no_grad():\n",
    "        teacher_logits = teacher_model(x)\n",
    "\n",
    "    # Soft labels (logits) from the teacher model\n",
    "    soft_labels = teacher_logits / temperature\n",
    "\n",
    "    # Create a new variable for x with requires_grad=True\n",
    "    x_ = Variable(x.data, requires_grad=True)\n",
    "\n",
    "    # Forward pass through the student model\n",
    "    h_ = net(x_)\n",
    "\n",
    "    # Compute the cross-entropy loss using soft labels\n",
    "    criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "    cost = criterion(F.log_softmax(h_ / temperature, dim=1), F.softmax(soft_labels, dim=1))\n",
    "\n",
    "    # Zero the gradients of the student model\n",
    "    net.zero_grad()\n",
    "\n",
    "    # Backward pass and compute gradients\n",
    "    cost.backward()\n",
    "\n",
    "    # Perturbation\n",
    "    pert = eps * x_.grad.detach().sign()\n",
    "\n",
    "    # Generate the adversarial example\n",
    "    x_adv = x_ + pert\n",
    "\n",
    "    # Forward pass through the adversarial example in the student model\n",
    "    h_adv = net(x_adv)\n",
    "\n",
    "    # Predicted label for the adversarial example\n",
    "    _, y_adv = torch.max(h_adv.data, 1)\n",
    "\n",
    "    return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5fd2d-8bc1-44b1-b806-7f5b6fd1b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Building new model..')\n",
    "\n",
    "# Define the teacher model (Assuming you have a ResNet18 teacher, replace it with your actual teacher model)\n",
    "teacher_model = ResNet18()\n",
    "teacher_model = teacher_model.to(device)\n",
    "if device == 'cuda':\n",
    "    teacher_model = torch.nn.DataParallel(teacher_model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Define the student model (Replace ResNet18() with your desired student model)\n",
    "student_model = ResNet18()\n",
    "student_model = student_model.to(device)\n",
    "if device == 'cuda':\n",
    "    student_model = torch.nn.DataParallel(student_model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Define the loss function for distillation\n",
    "def distillation_loss(outputs, teacher_outputs, temperature=3.0):\n",
    "    soft_outputs = F.softmax(outputs / temperature, dim=1)\n",
    "    soft_teacher_outputs = F.softmax(teacher_outputs / temperature, dim=1)\n",
    "    return nn.KLDivLoss()(F.log_softmax(outputs, dim=1), soft_teacher_outputs.detach() * temperature)\n",
    "\n",
    "# Define the criterion for the student model\n",
    "criterion_student = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer for both models\n",
    "optimizer_teacher = optim.SGD(teacher_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer_student = optim.SGD(student_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Define the learning rate scheduler for both optimizers\n",
    "scheduler_teacher = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_teacher, T_max=200)\n",
    "scheduler_student = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_student, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ababcfb-dfa5-4850-88d2-53e97418327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adv_distillation(epoch, net):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    eps = 8/255\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs_ = Variable(inputs.data, requires_grad=True)\n",
    "        h_ = net(inputs_)\n",
    "\n",
    "        cost = distillation_loss(h_, teacher_model(inputs_))  # Using distillation loss with teacher model\n",
    "\n",
    "        net.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        pert = eps * inputs_.grad.detach().sign()\n",
    "        x_adv = inputs_ + pert\n",
    "\n",
    "        optimizer_student.zero_grad()  # Using the existing optimizer for student model\n",
    "        outputs = net(x_adv)\n",
    "        loss = criterion_student(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_student.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "\n",
    "    return train_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3afea-526c-455c-b2d6-d8b381f117d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_adv = []\n",
    "test_losses_adv = []\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses_adv.append(train_adv_distillation(epoch, student_model))\n",
    "    test_losses_adv.append(test(epoch, student_model))\n",
    "    scheduler_student.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37be96-f325-4c54-968a-1e665d969b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4920da96-1f8f-4a63-bbe3-f8f85c5295e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adv_distillation(net, teacher_model, net_adv, eps, temperature):\n",
    "    accuracy = 0\n",
    "    net.train()\n",
    "    net_adv.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv, h_adv, y_adv, pert = FGSM_defense_distillation(net, teacher_model, inputs, targets, eps, temperature)\n",
    "\n",
    "        outputs = net_adv(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd64cf2-b302-4ac4-9cd5-1ac7c949571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in [4/255, 8/255, 12/255]:\n",
    "    accuracy = test_adv_distillation(\n",
    "        student_model,     # net\n",
    "        teacher_model,     # teacher_net\n",
    "        student_model,     # net_adv\n",
    "        eps,\n",
    "        temperature=3.0,   # Adjust temperature as needed\n",
    "    )\n",
    "    print(\"epsilon:\", eps, \"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c48bd0-9cb0-480b-87f8-76cd1f5efa1c",
   "metadata": {},
   "source": [
    "## PGD\n",
    " In the PGD attack, we repeat $\n",
    "\\delta:=\\mathcal{P}(\\delta+\\alpha \\nabla_{\\delta} l(\\theta, x, y))\n",
    "$\n",
    "for $t$ iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b0dc0d-9b59-4201-b70d-e546bf976242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(net,x,y,alpha,epsilon,iter):\n",
    "    '''\n",
    "    inputs:\n",
    "        net: the network through which we pass the inputs\n",
    "        x: the original example which we aim to perturb to make an adversarial example\n",
    "        y: the true label of x\n",
    "        alpha: step size\n",
    "        epsilon: perturbation budget \n",
    "        iter: number of iterations in the PGD algorithm\n",
    "\n",
    "    outputs:\n",
    "        x_adv : the adversarial example constructed from x\n",
    "        h_adv: output of the last softmax layer when applying net on x_adv \n",
    "        y_adv: predicted label for x_adv\n",
    "        pert: perturbation applied to x (x_adv - x)\n",
    "    '''\n",
    "\n",
    "    delta = torch.zeros_like(x, requires_grad=True)\n",
    "    for i in range(iter):\n",
    "        criterion=nn.CrossEntropyLoss()\n",
    "        loss = criterion(net(x + delta), y)\n",
    "        loss.backward()\n",
    "        delta.data = (delta + x.shape[0]*alpha*delta.grad.data).clamp(-epsilon,epsilon)\n",
    "        delta.grad.zero_()\n",
    "    pert = delta.detach()\n",
    "    x_adv = x + pert\n",
    "    h_adv = net(x_adv)\n",
    "    _,y_adv = torch.max(h_adv.data,1)\n",
    "    return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45670bec-3886-4643-af62-d13176c9e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Building new model..')\n",
    "net_pgd = ResNet18()\n",
    "net_pgd = net_pgd.to(device)\n",
    "if device == 'cuda':\n",
    "    net_pgd = torch.nn.DataParallel(net_pgd)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_pgd = optim.SGD(net_pgd.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler_pgd = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_pgd, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd140d-9253-4a78-a46d-f0c4e01f1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pgd(epoch, net, alpha, epsilon, iter):\n",
    "    \n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    eps=8/255\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv,_,_,_ = PGD(net,inputs,targets,alpha,epsilon,iter)\n",
    "\n",
    "        optimizer_pgd.zero_grad()\n",
    "        outputs = net(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_pgd.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "    return train_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c291c5-743a-4bd4-b8e8-d115971ac0df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_pgd=[]\n",
    "test_losses_pgd=[]\n",
    "epochs=3\n",
    "alpha=3/255\n",
    "epsilon=8/255\n",
    "iter=3\n",
    "for epoch in range(0,epochs):\n",
    "    train_losses_pgd.append(train_pgd(epoch, net_pgd, alpha, epsilon, iter))\n",
    "    test_losses_pgd.append(test(epoch, net_pgd))\n",
    "    scheduler_pgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3ffbc-e2db-4fe0-a338-d7e1c55debc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90192872-81e2-4b02-a36b-86ee99de9b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_PGD(net,net_pgd,alpha,eps,iter):\n",
    "    acc=0\n",
    "    net.train()\n",
    "    net_pgd.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            x_adv,_,_,_=PGD(net,inputs,targets,alpha,eps,iter)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = net_pgd(x_adv)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541eb4c4-27a4-47d5-8371-e5e52704de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=3/255\n",
    "eps=8/255\n",
    "acc1_pgd=[]\n",
    "for iter in [3,7,12]:\n",
    "    acc=test_PGD(net,net_pgd,alpha,eps,iter)\n",
    "    print(\"accuracy of net_pgd against PGD attack with iters=\",iter,\": \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a381ff2-0ba9-4f91-987b-a0b27134d5ff",
   "metadata": {},
   "source": [
    "### Defense Mechanism - Gaussian Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111e734-9c3d-4e2e-8eea-bc06c7b08c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD_with_Advanced_GaussianDefense(net, x, y, alpha, epsilon, iter, sigma, restart_interval=5, lambda_smooth=0.1):\n",
    "    '''\n",
    "    inputs:\n",
    "        net: the network through which we pass the inputs\n",
    "        x: the original example which we aim to perturb to make an adversarial example\n",
    "        y: the true label of x\n",
    "        alpha: step size\n",
    "        epsilon: perturbation budget \n",
    "        iter_pgd: number of iterations in the PGD algorithm\n",
    "        sigma: standard deviation for Gaussian noise\n",
    "        restart_interval: number of iterations before a random restart\n",
    "        lambda_smooth: coefficient for the smoothing regularization\n",
    "\n",
    "    outputs:\n",
    "        x_adv: the adversarial example constructed from x\n",
    "        h_adv: output of the last softmax layer when applying net on x_adv \n",
    "        y_adv: predicted label for x_adv\n",
    "        pert: perturbation applied to x (x_adv - x)\n",
    "    '''\n",
    "\n",
    "    delta = torch.zeros_like(x, requires_grad=True)\n",
    "\n",
    "    for i in range(iter):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        output = net(x + delta)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        # Smoothing regularization\n",
    "        smoothness_penalty = lambda_smooth * delta.norm(p=2)\n",
    "        loss += smoothness_penalty\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Apply Gaussian noise with adaptive scaling\n",
    "        with torch.no_grad():\n",
    "            gaussian_noise = torch.randn_like(delta) * sigma\n",
    "            gradient_norm = delta.grad.norm()\n",
    "            scaled_noise = gaussian_noise * (gradient_norm / (gradient_norm + 1e-10))\n",
    "            delta.data = (delta + alpha * delta.grad + scaled_noise).clamp(-epsilon, epsilon)\n",
    "\n",
    "        # Random restarts\n",
    "        if restart_interval > 0 and i % restart_interval == 0:\n",
    "            delta.data = torch.rand_like(x, requires_grad=True)\n",
    "\n",
    "        delta.grad.zero_()\n",
    "\n",
    "    pert = delta.detach()\n",
    "    x_adv = x + pert\n",
    "    h_adv = net(x_adv)\n",
    "    _, y_adv = torch.max(h_adv.data, 1)\n",
    "\n",
    "    return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e997b1b-571b-4a62-822e-be0651b7e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pgd_g(epoch, net, alpha, epsilon, iter, sigma):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    eps = 8 / 255\n",
    "    sigma = 0.2\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv, _, _, _ = PGD_with_Advanced_GaussianDefense(net, inputs, targets, alpha, epsilon, iter, sigma)\n",
    "\n",
    "        optimizer_pgd.zero_grad()\n",
    "        outputs = net(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_pgd.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "\n",
    "    return train_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb49355-ad92-45b8-972d-1b9889112597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_pgd = []\n",
    "test_losses_pgd = []\n",
    "epochs = 3\n",
    "alpha = 3 / 255\n",
    "epsilon = 8 / 255\n",
    "sigma = 0.2\n",
    "iter = 3  # Renamed iter to iter_pgd to avoid conflicts with the 'iter' keyword\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss_pgd = train_pgd_g(epoch, net_pgd, alpha, epsilon, iter, sigma)\n",
    "    test_loss_pgd = test(epoch, net_pgd)\n",
    "\n",
    "    train_losses_pgd.append(train_loss_pgd)\n",
    "    test_losses_pgd.append(test_loss_pgd)\n",
    "\n",
    "    scheduler_pgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da4e3a-e2f2-4c31-b05a-a69c4f1816e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be5e34-aeb7-48ed-bced-1c0081633df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_advanced_PGD(net, net_pgd, alpha, epsilon, iter, sigma):\n",
    "    acc = 0\n",
    "    net.train()\n",
    "    net_pgd.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sigma = 0.2\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # PGD with Advanced Gaussian Defense\n",
    "        x_adv, _, _, _ = PGD_with_Advanced_GaussianDefense(net, inputs, targets, alpha, epsilon, iter, sigma)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = net_pgd(x_adv)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fb38d-1416-4dd2-bfbf-8088600be867",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3 / 255\n",
    "eps = 8 / 255\n",
    "sigma = 0.2  # Define the appropriate value for sigma\n",
    "acc1_pgd = []\n",
    "\n",
    "for iter in [3, 7, 12]:\n",
    "    acc = test_advanced_PGD(net, net_pgd, alpha, eps, iter, sigma)  # Assuming you have a testloader\n",
    "    acc1_pgd.append(acc)\n",
    "    print(\"Accuracy of net_pgd against PGD attack with iters =\", iter, \": \", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
