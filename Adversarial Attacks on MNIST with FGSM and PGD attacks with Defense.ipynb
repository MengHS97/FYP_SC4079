{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e5b112-16d5-48cc-92f2-0f6dbf146344",
   "metadata": {},
   "source": [
    "# Adversarial Attacks on MNIST with FGSM and PGD attacks with Defense Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd4835-459e-4c42-9397-afb3ee93bdf0",
   "metadata": {},
   "source": [
    "In this notebook, we perform FGSM (targeted and non-targeted) and PGD attacks on the MNIST dataset using the Resnet18 model and build models to defend against these attacks using the Adversarial Training mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24222cb3-4f1e-4db9-8955-275db60780fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import *\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from resnet_mnist import *\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec4344e-3765-4409-bf10-4ff0f3497a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6ab20-5e8e-422c-aeee-c3abe1dc5c9d",
   "metadata": {},
   "source": [
    "<a name='name'></a>\n",
    "### Preparing train and test data and building Resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dcb133c-8198-4d52-b1b1-1f5e5bece932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "# Transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "# MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(\n",
    "    testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Classes\n",
    "classes = tuple(str(i) for i in range(10))  # Digits 0 to 9\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "# Use ResNet18 with 10 output classes for MNIST\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3635a499-0af7-4867-98d3-6d4a9a4c2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, net):\n",
    "    \n",
    "    '''\n",
    "    this function train net on training dataset\n",
    "    '''\n",
    "\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_accuracies = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "    return train_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "023ee932-b506-4384-b35f-8422b3c51d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, net):\n",
    "\n",
    "    '''\n",
    "    This function evaluate net on test dataset\n",
    "    '''\n",
    "\n",
    "    global acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_accuracies = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return test_loss/len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b40338a-db77-4e23-bc6a-798ba7a08953",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses=[]\n",
    "test_losses=[]\n",
    "epochs=3\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    train_losses.append(train(epoch, net))\n",
    "    test_losses.append(test(epoch, net))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970e4d92-50f6-4325-a1b2-6f5cda0f5b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee54220-bbed-45ee-a7c6-b5ff1e0401d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs=3\n",
    "plt.plot(np.arange(1,epochs+1),train_losses, label='train losses')\n",
    "plt.plot(np.arange(1,epochs+1), test_losses, label='test losses')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ad327-19a4-4220-a299-dc262641b13a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    accuracy = acc  # Assuming 'acc' is a global variable in your existing code\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e529e09-17a9-4cdd-a912-6b6994ad69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, epochs + 1), accuracies, label='Accuracy', marker='o')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c27f0-95df-4d2d-b5bd-7512558c3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=30, shuffle=False, num_workers=2)\n",
    "dataiter = iter(imgloader)\n",
    "org_images, org_labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c75dd7-1ea1-4da1-b60e-612bcf9f11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_labels = org_labels.to(device)\n",
    "org_images = org_images.to(device)\n",
    "print(org_images.shape)\n",
    "outputs= net(org_images)\n",
    "output=outputs.to(device)\n",
    "print(outputs.shape)\n",
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c6b3a-87ca-4b05-9a69-fac19c772665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "samples = []\n",
    "samples_labels = []\n",
    "samples_pred = []\n",
    "selected = [3,0,5,16,4,1,18,11]\n",
    "\n",
    "for i in selected:\n",
    "  samples.append(org_images[i])\n",
    "  samples_labels.append(org_labels[i])\n",
    "  samples_pred.append(outputs[i])\n",
    "samples = torch.stack(samples)\n",
    "samples_labels = torch.stack(samples_labels)\n",
    "samples_pred = torch.stack(samples_pred)\n",
    "imshow(torchvision.utils.make_grid(samples.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abc2a1-f3f7-4434-b265-9623e267f617",
   "metadata": {},
   "source": [
    "### FGSM attack function\n",
    "In the FGSM attack, we make adversarial examples using this equation:\n",
    "$x_{adv}=x_{benign}+\\epsilon * sign(\\nabla_{x_{benign}}l(\\theta, x, y))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326274f-8f9a-4212-a33f-90f9d5a0a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(net, x, y, eps):\n",
    "        '''\n",
    "        inputs:\n",
    "            net: the network through which we pass the inputs\n",
    "            x: the original example which we aim to perturb to make an adversarial example\n",
    "            y: the true label of x\n",
    "            eps: perturbation budget\n",
    "\n",
    "        outputs:\n",
    "            x_adv : the adversarial example constructed from x\n",
    "            h_adv: output of the last softmax layer when applying net on x_adv \n",
    "            y_adv: predicted label for x_adv\n",
    "            pert: perturbation applied to x (x_adv - x)\n",
    "        '''\n",
    "\n",
    "        x_ = Variable(x.data, requires_grad=True)\n",
    "        h_ = net(x_)\n",
    "        criterion= torch.nn.CrossEntropyLoss()\n",
    "        cost = criterion(h_, y)\n",
    "        net.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        #perturbation\n",
    "        pert= eps*x_.grad.detach().sign()\n",
    "        \n",
    "        x_adv = x_ + pert\n",
    "\n",
    "        h_adv = net(x_adv)\n",
    "        _,y_adv=torch.max(h_adv.data,1)\n",
    "        return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88b51b4-35ee-404a-bc83-6c1eb0de2136",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print()\n",
    "print('from left to right: (1/eps) perturbation, original image, adversarial example')\n",
    "print()\n",
    "for i in selected:\n",
    "    eps=1/255\n",
    "    while True:\n",
    "        x_adv, h_adv, y_adv, pert=FGSM(net, org_images[i].unsqueeze_(0),org_labels[i].unsqueeze_(0),eps)\n",
    "        if y_adv.item()==org_labels[i].item():\n",
    "            eps=eps+(1/255)\n",
    "        else:\n",
    "            break\n",
    "    print(\"true label:\", org_labels[i].item(), \"adversary label:\", y_adv.item())\n",
    "    triple=[]\n",
    "    with torch.no_grad():\n",
    "        triple.append((1/eps)*pert.detach().clone().squeeze_(0))\n",
    "        triple.append(org_images[i])\n",
    "        triple.append(x_adv.detach().clone().squeeze_(0))\n",
    "        triple=torch.stack(triple)\n",
    "        grid = torchvision.utils.make_grid(triple.cpu()/2+0.5)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67add626-a913-40a9-97f3-61141316484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Building new model..')\n",
    "net_adv = ResNet18()\n",
    "net_adv = net_adv.to(device)\n",
    "if device == 'cuda':\n",
    "    net_adv = torch.nn.DataParallel(net_adv)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_adv = optim.SGD(net_adv.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler_adv = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_adv, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920e79f-de81-4f00-8d77-4cfca4e3f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adv(epoch, net):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    eps=8/255\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs_ = Variable(inputs.data, requires_grad=True)\n",
    "        h_ = net(inputs_)\n",
    "\n",
    "        cost = criterion(h_, targets)\n",
    "\n",
    "        net.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        pert= eps*inputs_.grad.detach().sign()\n",
    "        x_adv = inputs_ + pert\n",
    "\n",
    "        optimizer_adv.zero_grad()\n",
    "        outputs = net(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_adv.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "    return train_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc08437-0641-42ce-9232-34b59d668e83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_adv=[]\n",
    "test_losses_adv=[]\n",
    "epochs=3\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    train_losses_adv.append(train_adv(epoch, net_adv))\n",
    "    test_losses_adv.append(test(epoch, net_adv))\n",
    "    scheduler_adv.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d65f4-531f-4c2b-8832-5a40a0416ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on unperturbed test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59704200-d647-49fb-b2fb-6e5321e8c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,epochs+1),train_losses_adv, label='train - adversary')\n",
    "plt.plot(np.arange(1,epochs+1), test_losses_adv, label='test - adversary')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f1b98-9134-47c1-bb8c-75fedddbcde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adv(net, net_adv, eps):\n",
    "    accuracy=0\n",
    "    net.train()\n",
    "    net_adv.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv, h_adv, y_adv, pert = FGSM (net, inputs, targets, eps)\n",
    "            \n",
    "        outputs = net_adv(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c055e7aa-aeb5-4682-9a72-d227b2e2785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in [4/255, 8/255, 12/255]:\n",
    "    accuracy=test_adv(net, net_adv, eps)\n",
    "    print(\"epsilon:\", eps, \"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32f193-4ec6-4b98-8a55-2f2dbd46a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_with_AdvancedGaussianDefense(net, x, y, eps, sigma=0.2, alpha=0.2):\n",
    "    '''\n",
    "    inputs:\n",
    "        net: the network through which we pass the inputs\n",
    "        x: the original example which we aim to perturb to make an adversarial example\n",
    "        y: the true label of x\n",
    "        eps: perturbation budget\n",
    "        sigma: standard deviation of the Gaussian noise\n",
    "        alpha: spatially varying factor for Gaussian noise\n",
    "\n",
    "    outputs:\n",
    "        x_adv : the adversarial example constructed from x with advanced Gaussian defense\n",
    "        h_adv: output of the last softmax layer when applying net on x_adv \n",
    "        y_adv: predicted label for x_adv\n",
    "        pert: perturbation applied to x (x_adv - x)\n",
    "    '''\n",
    "\n",
    "    x_ = torch.autograd.Variable(x.data, requires_grad=True)\n",
    "    \n",
    "    # Forward pass\n",
    "    h_ = net(x_)\n",
    "    \n",
    "    # Calculate the cross-entropy loss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    cost = criterion(h_, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    net.zero_grad()\n",
    "    cost.backward()\n",
    "    \n",
    "    # Perturbation using FGSM\n",
    "    pert = eps * x_.grad.detach().sign()\n",
    "    \n",
    "    # Create a spatially varying defense factor\n",
    "    defense_factor = alpha * torch.randn_like(x_)\n",
    "    \n",
    "    # Apply spatially varying Gaussian defense to the perturbation\n",
    "    pert = pert + defense_factor * sigma\n",
    "    \n",
    "    # Create the adversarial example\n",
    "    x_adv = x_ + pert\n",
    "    \n",
    "    # Forward pass on the adversarial example\n",
    "    h_adv = net(x_adv)\n",
    "    \n",
    "    # Get the predicted label for the adversarial example\n",
    "    _, y_adv = torch.max(h_adv.data, 1)\n",
    "    \n",
    "    return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e298f9-06de-4dd1-8c42-d6f591bcf2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adv_d(epoch, net):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sigma = 0.2\n",
    "    eps = 8 / 255\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs_ = torch.autograd.Variable(inputs.data, requires_grad=True)\n",
    "        h_ = net(inputs_)\n",
    "\n",
    "        cost = criterion(h_, targets)\n",
    "\n",
    "        net.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        # Perturbation using FGSM\n",
    "        pert = eps * inputs_.grad.detach().sign()\n",
    "        \n",
    "        # Apply Gaussian defense to the perturbation\n",
    "        pert = pert + torch.randn_like(inputs_) * sigma\n",
    "\n",
    "        x_adv = inputs_ + pert\n",
    "\n",
    "        optimizer_adv.zero_grad()\n",
    "\n",
    "        # Forward pass on the adversarial example\n",
    "        outputs = net(x_adv)\n",
    "\n",
    "        # You may want to apply Gaussian defense to the adversarial example here\n",
    "        pert_adv = torch.randn_like(x_adv) * sigma\n",
    "        x_adv = x_adv + pert_adv\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_adv.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "    \n",
    "    return train_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60320a3-ea36-42ed-9f8a-9e028cd88008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_adv_g = []\n",
    "test_losses_adv_g = []\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses_adv_g.append(train_adv_d(epoch, net_adv))\n",
    "    test_losses_adv_g.append(test(epoch, net_adv))\n",
    "    scheduler_adv.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f002058a-721e-4add-8162-119f62f80665",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on unperturbed test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3a7e8-7d71-4b83-b7bd-886e91ff81b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,epochs+1),train_losses_adv_g, label='train - adversary')\n",
    "plt.plot(np.arange(1,epochs+1), test_losses_adv_g, label='test - adversary')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2eda1-aa6a-4c58-b684-1e8340642022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adv_d(net, net_adv, eps, sigma=0.2):\n",
    "    accuracy = 0\n",
    "    net.train()\n",
    "    net_adv.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Call FGSM_with_AdvancedGaussianDefense to generate adversarial examples\n",
    "        x_adv, h_adv, y_adv, pert = FGSM_with_AdvancedGaussianDefense(net, inputs, targets, eps, sigma)\n",
    "\n",
    "        outputs = net_adv(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39341b22-57de-469e-a5a9-73b315134fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in [4/255, 8/255, 12/255]:\n",
    "    accuracy = test_adv_d(net, net_adv, eps, sigma=0.2)\n",
    "    print(\"epsilon:\", eps, \"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484e158-96e9-4c30-ac08-400e8a72451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM_defense_distillation(net, teacher_model, x, y, eps, temperature=3.0):\n",
    "    '''\n",
    "    inputs:\n",
    "        net: the student network through which we pass the inputs\n",
    "        teacher_model: the pre-trained teacher model for defense distillation\n",
    "        x: the original example which we aim to perturb to make an adversarial example\n",
    "        y: the true label of x\n",
    "        eps: perturbation budget\n",
    "        temperature: temperature parameter for softmax\n",
    "\n",
    "    outputs:\n",
    "        x_adv : the adversarial example constructed from x\n",
    "        h_adv: output of the last softmax layer when applying net on x_adv \n",
    "        y_adv: predicted label for x_adv\n",
    "        pert: perturbation applied to x (x_adv - x)\n",
    "    '''\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    net.eval()\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Forward pass through the teacher model\n",
    "    with torch.no_grad():\n",
    "        teacher_logits = teacher_model(x)\n",
    "\n",
    "    # Soft labels (logits) from the teacher model\n",
    "    soft_labels = teacher_logits / temperature\n",
    "\n",
    "    # Create a new variable for x with requires_grad=True\n",
    "    x_ = Variable(x.data, requires_grad=True)\n",
    "\n",
    "    # Forward pass through the student model\n",
    "    h_ = net(x_)\n",
    "\n",
    "    # Compute the cross-entropy loss using soft labels\n",
    "    criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "    cost = criterion(F.log_softmax(h_ / temperature, dim=1), F.softmax(soft_labels, dim=1))\n",
    "\n",
    "    # Zero the gradients of the student model\n",
    "    net.zero_grad()\n",
    "\n",
    "    # Backward pass and compute gradients\n",
    "    cost.backward()\n",
    "\n",
    "    # Perturbation\n",
    "    pert = eps * x_.grad.detach().sign()\n",
    "\n",
    "    # Generate the adversarial example\n",
    "    x_adv = x_ + pert\n",
    "\n",
    "    # Forward pass through the adversarial example in the student model\n",
    "    h_adv = net(x_adv)\n",
    "\n",
    "    # Predicted label for the adversarial example\n",
    "    _, y_adv = torch.max(h_adv.data, 1)\n",
    "\n",
    "    return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162bfae-f368-4492-9a47-7d870ef3e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Building new model..')\n",
    "\n",
    "# Define the teacher model (Assuming you have a ResNet18 teacher, replace it with your actual teacher model)\n",
    "teacher_model = ResNet18()\n",
    "teacher_model = teacher_model.to(device)\n",
    "if device == 'cuda':\n",
    "    teacher_model = torch.nn.DataParallel(teacher_model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Define the student model (Replace ResNet18() with your desired student model)\n",
    "student_model = ResNet18()\n",
    "student_model = student_model.to(device)\n",
    "if device == 'cuda':\n",
    "    student_model = torch.nn.DataParallel(student_model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Define the loss function for distillation\n",
    "def distillation_loss(outputs, teacher_outputs, temperature=3.0):\n",
    "    soft_outputs = F.softmax(outputs / temperature, dim=1)\n",
    "    soft_teacher_outputs = F.softmax(teacher_outputs / temperature, dim=1)\n",
    "    return nn.KLDivLoss()(F.log_softmax(outputs, dim=1), soft_teacher_outputs.detach() * temperature)\n",
    "\n",
    "# Define the criterion for the student model\n",
    "criterion_student = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer for both models\n",
    "optimizer_teacher = optim.SGD(teacher_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer_student = optim.SGD(student_model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Define the learning rate scheduler for both optimizers\n",
    "scheduler_teacher = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_teacher, T_max=200)\n",
    "scheduler_student = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_student, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c2c80-accc-4123-8672-2639fbd1f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adv_distillation(epoch, net):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    eps = 8/255\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        inputs_ = Variable(inputs.data, requires_grad=True)\n",
    "        h_ = net(inputs_)\n",
    "\n",
    "        cost = distillation_loss(h_, teacher_model(inputs_))  # Using distillation loss with teacher model\n",
    "\n",
    "        net.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        pert = eps * inputs_.grad.detach().sign()\n",
    "        x_adv = inputs_ + pert\n",
    "\n",
    "        optimizer_student.zero_grad()  # Using the existing optimizer for student model\n",
    "        outputs = net(x_adv)\n",
    "        loss = criterion_student(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_student.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "\n",
    "    return train_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64145d6d-2b0d-4b83-a3c8-514d1c1ca910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_adv = []\n",
    "test_losses_adv = []\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses_adv.append(train_adv_distillation(epoch, student_model))\n",
    "    test_losses_adv.append(test(epoch, student_model))\n",
    "    scheduler_student.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833aedd5-ee1d-4ea6-af6d-ab468b6841fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df9d1da-8527-4124-be2e-2739a69e7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adv_distillation(net, teacher_model, net_adv, eps, temperature):\n",
    "    accuracy = 0\n",
    "    net.train()\n",
    "    net_adv.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv, h_adv, y_adv, pert = FGSM_defense_distillation(net, teacher_model, inputs, targets, eps, temperature)\n",
    "\n",
    "        outputs = net_adv(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362d434a-577d-4c81-820f-df2ba7e8fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in [4/255, 8/255, 12/255]:\n",
    "    accuracy = test_adv_distillation(\n",
    "        student_model,     # net\n",
    "        teacher_model,     # teacher_net\n",
    "        student_model,     # net_adv\n",
    "        eps,\n",
    "        temperature=3.0,   # Adjust temperature as needed\n",
    "    )\n",
    "    print(\"epsilon:\", eps, \"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee0f3e-79ce-4628-9790-f48ba7c3674d",
   "metadata": {},
   "source": [
    "## PGD\n",
    " In the PGD attack, we repeat $\n",
    "\\delta:=\\mathcal{P}(\\delta+\\alpha \\nabla_{\\delta} l(\\theta, x, y))\n",
    "$\n",
    "for $t$ iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b990eec-638e-46b4-9c2f-cd83056d8892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD(net,x,y,alpha,epsilon,iter):\n",
    "    '''\n",
    "    inputs:\n",
    "        net: the network through which we pass the inputs\n",
    "        x: the original example which we aim to perturb to make an adversarial example\n",
    "        y: the true label of x\n",
    "        alpha: step size\n",
    "        epsilon: perturbation budget \n",
    "        iter: number of iterations in the PGD algorithm\n",
    "\n",
    "    outputs:\n",
    "        x_adv : the adversarial example constructed from x\n",
    "        h_adv: output of the last softmax layer when applying net on x_adv \n",
    "        y_adv: predicted label for x_adv\n",
    "        pert: perturbation applied to x (x_adv - x)\n",
    "    '''\n",
    "\n",
    "    delta = torch.zeros_like(x, requires_grad=True)\n",
    "    for i in range(iter):\n",
    "        criterion=nn.CrossEntropyLoss()\n",
    "        loss = criterion(net(x + delta), y)\n",
    "        loss.backward()\n",
    "        delta.data = (delta + x.shape[0]*alpha*delta.grad.data).clamp(-epsilon,epsilon)\n",
    "        delta.grad.zero_()\n",
    "    pert = delta.detach()\n",
    "    x_adv = x + pert\n",
    "    h_adv = net(x_adv)\n",
    "    _,y_adv = torch.max(h_adv.data,1)\n",
    "    return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff3927-df0a-42a6-b6d7-afe815e0d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Building new model..')\n",
    "net_pgd = ResNet18()\n",
    "net_pgd = net_pgd.to(device)\n",
    "if device == 'cuda':\n",
    "    net_pgd = torch.nn.DataParallel(net_pgd)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_pgd = optim.SGD(net_pgd.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler_pgd = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_pgd, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b6d8d-e5a3-4bed-853b-af459d8c9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pgd(epoch, net, alpha, epsilon, iter):\n",
    "    \n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    eps=8/255\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv,_,_,_ = PGD(net,inputs,targets,alpha,epsilon,iter)\n",
    "\n",
    "        optimizer_pgd.zero_grad()\n",
    "        outputs = net(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_pgd.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "    return train_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8fc97-d25f-4fdd-80cb-5daa77c25c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_pgd=[]\n",
    "test_losses_pgd=[]\n",
    "epochs=3\n",
    "alpha=3/255\n",
    "epsilon=8/255\n",
    "iter=3\n",
    "for epoch in range(0,epochs):\n",
    "    train_losses_pgd.append(train_pgd(epoch, net_pgd, alpha, epsilon, iter))\n",
    "    test_losses_pgd.append(test(epoch, net_pgd))\n",
    "    scheduler_pgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed8af7-0bb3-4339-a5c3-751c5c0763c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906605e8-5b74-43d6-bf7d-c429c6ecb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_PGD(net,net_pgd,alpha,eps,iter):\n",
    "    acc=0\n",
    "    net.train()\n",
    "    net_pgd.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            x_adv,_,_,_=PGD(net,inputs,targets,alpha,eps,iter)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = net_pgd(x_adv)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += targets.size(0)\n",
    "                correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa4ed4-c394-4e4c-ba91-184b3498fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=3/255\n",
    "eps=8/255\n",
    "acc1_pgd=[]\n",
    "for iter in [3,7,12]:\n",
    "    acc=test_PGD(net,net_pgd,alpha,eps,iter)\n",
    "    print(\"accuracy of net_pgd against PGD attack with iters=\",iter,\": \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5e71e9-b679-4ab9-83ab-b5d4d9798f2e",
   "metadata": {},
   "source": [
    "### Defense Mechanism - Gaussian Noise Defense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0a314-3afa-440f-9bab-6d27c3e0dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD_with_Gaussian_Defense(net, x, y, alpha, epsilon, iter, sigma):\n",
    "    '''\n",
    "    inputs:\n",
    "        net: the network through which we pass the inputs\n",
    "        x: the original example which we aim to perturb to make an adversarial example\n",
    "        y: the true label of x\n",
    "        alpha: step size\n",
    "        epsilon: perturbation budget \n",
    "        iter: number of iterations in the PGD algorithm\n",
    "        sigma: standard deviation for Gaussian defense\n",
    "\n",
    "    outputs:\n",
    "        x_adv : the adversarial example constructed from x\n",
    "        h_adv: output of the last softmax layer when applying net on x_adv \n",
    "        y_adv: predicted label for x_adv\n",
    "        pert: perturbation applied to x (x_adv - x)\n",
    "    '''\n",
    "\n",
    "    delta = torch.zeros_like(x, requires_grad=True)\n",
    "    for i in range(iter):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(net(x + delta), y)\n",
    "        loss.backward()\n",
    "\n",
    "        # PGD step\n",
    "        delta.data = (delta + alpha * delta.grad.data).clamp(-epsilon, epsilon)\n",
    "\n",
    "        # Gaussian defense step\n",
    "        gaussian_perturbation = torch.randn_like(delta) * sigma\n",
    "        delta.data = (delta + gaussian_perturbation).clamp(-epsilon, epsilon)\n",
    "\n",
    "        delta.grad.zero_()\n",
    "\n",
    "    pert = delta.detach()\n",
    "    x_adv = x + pert\n",
    "    h_adv = net(x_adv)\n",
    "    _, y_adv = torch.max(h_adv.data, 1)\n",
    "    return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d0b61-e76d-40c7-ba37-17b55ecef1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pgd_g(epoch, net, alpha, epsilon, iter, sigma):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    eps = 8 / 255\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv, _, _, _ = PGD_with_Gaussian_Defense(net, inputs, targets, alpha, epsilon, iter, sigma)\n",
    "\n",
    "        optimizer_pgd.zero_grad()\n",
    "        outputs = net(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_pgd.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "\n",
    "    return train_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91b420-b2fa-417a-89dd-3e63032c0443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_pgd = []\n",
    "test_losses_pgd = []\n",
    "epochs = 3\n",
    "alpha = 3 / 255\n",
    "epsilon = 8 / 255\n",
    "sigma = 0.2\n",
    "iter = 3  # Renamed iter to iter_pgd to avoid conflicts with the 'iter' keyword\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss_pgd = train_pgd_g(epoch, net_pgd, alpha, epsilon, iter, sigma)\n",
    "    test_loss_pgd = test(epoch, net_pgd)\n",
    "\n",
    "    train_losses_pgd.append(train_loss_pgd)\n",
    "    test_losses_pgd.append(test_loss_pgd)\n",
    "\n",
    "    scheduler_pgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903a417-2202-4da5-8c49-8768580a45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7597015-bdfd-4783-86ef-d10162f7f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_advanced_PGD(net, net_pgd, alpha, epsilon, iter, sigma):\n",
    "    acc = 0\n",
    "    net.train()\n",
    "    net_pgd.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # PGD with Advanced Gaussian Defense\n",
    "        x_adv, _, _, _ = PGD_with_Gaussian_Defense(net, inputs, targets, alpha, epsilon, iter, sigma)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = net_pgd(x_adv)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d8e45-5ae5-4882-9770-2aad6d4f143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3 / 255\n",
    "eps = 8 / 255\n",
    "sigma = 0.2  # Define the appropriate value for sigma\n",
    "acc1_pgd = []\n",
    "\n",
    "for iter in [3, 7, 12]:\n",
    "    acc = test_advanced_PGD(net, net_pgd, alpha, eps, iter, sigma)  # Assuming you have a testloader\n",
    "    acc1_pgd.append(acc)\n",
    "    print(\"Accuracy of net_pgd against PGD attack with iters =\", iter, \": \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be64d9-3c2b-4544-9fe7-a87f8729b483",
   "metadata": {},
   "source": [
    "### Defense Mechanism - Defense Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607714f-3db4-4aed-ac09-20f374794a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PGD_with_distillation(net, x, y, alpha, epsilon, iter, teacher_net, temperature=3):\n",
    "    '''\n",
    "    inputs:\n",
    "        net: the network through which we pass the inputs (student network)\n",
    "        x: the original example which we aim to perturb to make an adversarial example\n",
    "        y: the true label of x\n",
    "        alpha: step size\n",
    "        epsilon: perturbation budget \n",
    "        iter: number of iterations in the PGD algorithm\n",
    "        teacher_net: the network used for defense distillation (teacher network)\n",
    "        temperature: temperature parameter for softmax function\n",
    "\n",
    "    outputs:\n",
    "        x_adv : the adversarial example constructed from x\n",
    "        h_adv: output of the last softmax layer when applying net on x_adv \n",
    "        y_adv: predicted label for x_adv\n",
    "        pert: perturbation applied to x (x_adv - x)\n",
    "    '''\n",
    "\n",
    "    delta = torch.zeros_like(x, requires_grad=True)\n",
    "    for i in range(iter):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Get the output of the teacher network\n",
    "        with torch.no_grad():\n",
    "            teacher_output = teacher_net(x + delta) / temperature\n",
    "        \n",
    "        # Compute the Kullback-Leibler divergence loss between student and teacher outputs\n",
    "        loss_distillation = nn.KLDivLoss()(nn.functional.log_softmax(net(x + delta) / temperature, dim=1),\n",
    "                                            nn.functional.softmax(teacher_output, dim=1))\n",
    "        \n",
    "        # Compute the Cross Entropy Loss for the student network\n",
    "        loss_classification = criterion(net(x + delta), y)\n",
    "        \n",
    "        # Total loss is a combination of distillation loss and classification loss\n",
    "        loss = loss_classification + loss_distillation\n",
    "        \n",
    "        loss.backward()\n",
    "        delta.data = (delta + alpha * delta.grad.data.sign()).clamp(-epsilon, epsilon)\n",
    "        delta.grad.zero_()\n",
    "    \n",
    "    pert = delta.detach()\n",
    "    x_adv = x + pert\n",
    "    h_adv = net(x_adv)\n",
    "    _, y_adv = torch.max(h_adv.data, 1)\n",
    "    \n",
    "    return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ab60e-8baa-4801-bdfb-873feb59bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> Building new model..')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define teacher network (ResNet18)\n",
    "teacher_net = ResNet18()\n",
    "teacher_net = teacher_net.to(device)\n",
    "if device == 'cuda':\n",
    "    teacher_net = torch.nn.DataParallel(teacher_net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Define student network (ResNet18)\n",
    "student_net = ResNet18()\n",
    "student_net = student_net.to(device)\n",
    "if device == 'cuda':\n",
    "    student_net = torch.nn.DataParallel(student_net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Optimizer for teacher network\n",
    "optimizer_teacher = optim.SGD(teacher_net.parameters(), lr=lr,\n",
    "                              momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Optimizer for student network\n",
    "optimizer_student = optim.SGD(student_net.parameters(), lr=lr,\n",
    "                              momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# Scheduler for teacher network\n",
    "scheduler_teacher = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_teacher, T_max=200)\n",
    "\n",
    "# Scheduler for student network\n",
    "scheduler_student = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_student, T_max=200)\n",
    "\n",
    "# Rest of the model training setup\n",
    "criterion_student = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2118c1-eee6-47a7-9dd7-ab84cfd6a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pgd_d(epoch, net, alpha, epsilon, iter, teacher_net, temperature=3):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # PGD with defense distillation\n",
    "        x_adv, _, _, _ = PGD_with_distillation(net, inputs, targets, alpha, epsilon, iter, teacher_net, temperature)\n",
    "\n",
    "        optimizer_student.zero_grad()\n",
    "        outputs = net(x_adv)\n",
    "        \n",
    "        # Calculate loss using the original targets\n",
    "        loss = criterion_student(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer_student.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(batch_idx)\n",
    "\n",
    "    return train_loss / len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a5da0-81cd-4c0a-9d75-77652200e13b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses_pgd = []\n",
    "test_losses_pgd = []\n",
    "epochs = 3\n",
    "alpha = 3 / 255\n",
    "epsilon = 8 / 255\n",
    "iter = 3\n",
    "temperature = 3.0  # You need to define the temperature value\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss_pgd = train_pgd_d(epoch, student_net, alpha, epsilon, iter, teacher_net, temperature)\n",
    "    test_loss_pgd = test(epoch, student_net)  # Assuming you have defined the test function\n",
    "\n",
    "    train_losses_pgd.append(train_loss_pgd)\n",
    "    test_losses_pgd.append(test_loss_pgd)\n",
    "\n",
    "    scheduler_student.step()  # Assuming you want to schedule the student network's optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88244c5-9542-4b00-9321-82cd3aba0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of the network on the test images: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea4ff6-5cc1-40f1-b790-c065fe47e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_PGD_with_distillation(net, net_pgd, alpha, eps, iter, teacher_net, temperature):\n",
    "    acc = 0\n",
    "    net.train()\n",
    "    net_pgd.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv, _, _, _ = PGD_with_distillation(net, inputs, targets, alpha, eps, iter, teacher_net, temperature)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = net_pgd(x_adv)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd47516-c8c7-4e5f-b011-42a78698ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3 / 255\n",
    "eps = 8 / 255\n",
    "acc1_pgd = []\n",
    "\n",
    "# Define the iterations for the PGD attack\n",
    "iterations = [3, 7, 12]\n",
    "\n",
    "for iter in iterations:\n",
    "    acc = test_PGD_with_distillation(net, net_pgd, alpha, eps, iter, teacher_net, temperature)\n",
    "    print(\"Accuracy of net_pgd against PGD attack with iters =\", iter, \": \", acc)\n",
    "    acc1_pgd.append(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
