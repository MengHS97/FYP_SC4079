# Final Year Project: Cryptography Techniques to Defend Neural Network from Adversarial Attacks

Welcome to our comprehensive project archive, where we critically analyze and compare two dominant deep learning frameworks: ResNet18 and VGG16. We use a variety of datasets to evaluate these models under numerous data environments. Our goal is to understand the performance capabilities of these frameworks under different data conditions, providing insights that could guide future research and implementations.

## Project Overview

In this investigation, we delve deeply into the performance intricacies of the ResNet18 and VGG16 models, trained and assessed on four distinct datasets: CIFAR10, CIFAR100, FashionMNIST, and MNIST. These datasets were chosen as they collectively represent a broad spectrum of complexities and characteristics. By investigating these models under various conditions, we aim to gain a better understanding of how different neural network architectures respond to these challenges.

Our repository also includes implementation and analysis of defense mechanisms such as the Gaussian Noise Defense and Defense Distillation. Furthermore, we introduce a novel defense mechanism involving neuron shuffling in the neural network models. This innovative approach is used for running experiments to further our understanding of potential defense strategies against adversarial attacks on neural networks.

## ResNet Model
- The python is use to run on the datasets on CIFAR10 with the adversarial attacks on FGSM & PGD with integration on the defense mechanism.

- Adversarial Attacks on CIFAR-100 with FGSM and PGD attacks with Defense.ipynb: The python is use to run on the datasets on CIFAR100 with the adversarial attacks on FGSM & PGD with integration on the defense mechanism.

- Adversarial Attacks on FashionMNIST with FGSM and PGD attacks with Defense.ipynb: The python is use to run on the datasets on FashionMNIST with the adversarial attacks on FGSM & PGD with integration on the defense mechanism.

 - The python is use to run on the datasets on MNIST with the adversarial attacks on FGSM & PGD with integration on the defense mechanism.

## VGG Model
- VGG_Implementation_CIFAR10 with Defense.ipynb: The python is use to run on the datasets on CIFAR10 with VGG with the adversarial attacks on FGSM & PGD with integration on the defense mechanism.

- VGG_Implementation_CIFAR100 with Defense.ipynb: The python is use to run on the datasets on CIFAR100 with VGG with the adversarial attacks on FGSM & PGD with integration on the defense mechanism.

# Carlini & Wagner Adversarial Attacks

There is a directory contains essential files that are crucial for running experiments and understanding the implementation of the Carlini & Wagner Adversarial Attacks.

Here you'll find the necessary resources to get started with exploring the fascinating world of adversarial machine learning through the lens of the C&W method.

# Additional - Proposed Defense Mechanism
- CIFAR-10 with Neuron Shuffling.ipynb: The current file use for running and experimenting on the new proposed defense mechanism.
